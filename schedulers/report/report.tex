\documentclass{acm_proc_article-sp}

\begin{document}

\title{CS211 Assignment 2: Scheduling}
\numberofauthors{1}
\author{
  \alignauthor 
  Samuel B Sherar\\
  \email{sbs1@aber.ac.uk}\
}

\maketitle

\section{Introduction}
In this report I will be analysing the effects of 4 different scheduling algorithms: First In First Out, Shortest Time Remaining, Round Robin \& Lottery Schedulers. During my experiments, I will be conducting tests on different sized datasets and then analysing different aspects of the environment, such as Idle time, Context switching and mean time for an average job.

The analysis of a scheduling algorithm is important in the Operating System so that every job gets a fair amount of processing time depending on how important it is. However there are issues with certain scheduling algorithms, as there could be points where a job could be waiting for Input/Output (I/O Blocked), and not utilising idling processing time on the CPU, or issues where a job doesn't get access to the CPU due to being a low priority or being pushed to the end due to shorter jobs taking priority, this is called Starvation of a process. 

%TODO extend and expand
\section{Implementation}

When implementing the algorithms, each algorithm was created and tested on each given test file and stepped through to check the implementation was doing as expected. This means that when the additional data files with the larger amount of instructions will run without errors, which might be lost when run through such a large amounts of data.

\subsection{Round Robin Scheduler}

To implement the Round Robin scheduler, we can utilise the First Come First Served scheduler given, but modifying a couple of key aspects. The first thing to do was change the \texttt{ArrayList} to a \texttt{LinkedList} to gauruntee that the returned job will always be entered at the end. We can also add 2 class scoped variables, one specifying the amount of cycles before removing the job at the head of the queue, and one to count how many cycles it has been since we started the job. The main reason for this to create a single edit point, instead of hard coding it so it is easier to analyse the difference between different cycle counts.

\subsection{Shortest Time Remaining Scheduler}

To create the Shortest Time Remaining algorithm, the idea was to check the time remaining when adding the job to the queue by retrieving the \texttt{Job.length()} minus \texttt{Job.get\-ProgramCount()}. Using the documentation I wanted to use \texttt{Job.getElapsedTime()}, but during debugging my code, it seemed to return 0 constantly, and therefore not suitable to get consistent results.

\subsection{Lottery Scheduler}

The lottery scheduler was implemented as a worst case senario. This was done by every time a job is returned from processing, it takes each job on the queue, and cycles through adding the job multiple times depending on the priority of the job, then \texttt{Collections.shuffle} randomised the tickets while using a specified random class for the randomness. This means that each time it was run, the seed was changed to the current milliseconds currently elapsed from the UNIX epoch, and therefore stop issues arising when running the algorithm than more than 1 time.

\section{Method}

To gather a good amount of data, we will be running each algorithm through 3 different datasets: one which was given to me with the scheduler, which has a mix of CPU, I/O blocked and mix of the two; another data file 500 instructions in total across multiple processes, and the last file with 10,000 instructions. 

For unbiased results with the Lottery Scheduler, it will be run through each dataset 10 times and applying Standard Deviation to the results to remove any anomalies. This will give a better mean and average across all the results, and more consistent data if it was actually implemented on a system. To apply the standard deviation, I will be using the mean time of the jobs from the single run. 

\section{Results}

For the results, the names of the algorithms have been reduced to acronyms for ease of reading in the table. These are as follows:

\begin{itemize}
  \item FCFS -- First Come First Served
  \item RR -- Round Robin
  \item STR -- Shortest Time Remaining
  \item L -- Lottery
\end{itemize}

There are 5 pieces of data which will be analysed: how quick the first job will be completed; the mean duration of the jobs, the total CPU time taken processing each job, how many times the job has been switched between the queue and the CPU, and how many ticks the CPU has been idle while waiting for an I/O blocked process to unblock itself.

%TODO state the outcome

\subsection{Test File}

This is the result table of the \texttt{Test\-.jobs}, which was given to test against. 

\begin{tabular}{| l | c | c | c | c | c |}
  \hline
  Name & First & Duration & CPU Time & Switches &  Idle \\
  \hline
  FCFS & 13 & 48 & 75 & 10 & 6 \\
  RR & 43 & 56 & 69 & 26 & 0 \\
  STR & 13 & 43 & 81 & 11 & 12 \\
  L & 46.75  & 55.8 & 65 & 53.2 & 1.2 \\
  \hline
\end{tabular}


\subsection{500 Instructions}

This table was created from running the algorithms through a file which had 500 instructions combined between IO and CPU time.

\begin{tabular}{| l | c | c | c | c | c |}
  \hline
  Name & First & Duration & CPU Time & Switches &  Idle \\
  \hline
  FCFS & 71 & 278 & 370 & 29 & 8 \\
  RR & 231 & 292 & 362 & 113 & 0 \\
  STR & 49 & 189 & 362 & 48 & 0 \\
  L & 204 & 273.4 & 362 & 281.6 & 0 \\
  \hline
\end{tabular}


\subsection{10,000 Instructions}

This was the extended instruction set with approximitely 10,000 instructions split between IO and CPU times.

\begin{tabular}{| l | c | c | c | c | c |}
  \hline
  Name & First & Duration & CPU Time & Switches &  Idle \\
  \hline
  FCFS & 161 & 2389 & 3118 & 50 & 71 \\
  RR & 946 & 2093 & 3047 & 760 & 0 \\
  STR & 161 & 1400 & 3448 & 98 & 401\\
  L & 751.6 & 2517.3 & 2550 & 1026.5 & 33.8 \\ 
  \hline
\end{tabular}

\section{Discussion}

\section{Improvements}


\section{Conclusion}

\section{Executive Summery}

\end{document}
